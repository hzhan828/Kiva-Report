{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Variables + RNN on pre-trained Word2vec embedding word vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down = pd.read_csv('/home/hzhan828/kiva/down.csv')\n",
    "w2vdict = np.load('/home/hzhan828/kiva/w2vdict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vdict = np.load('/Users/zhanhaochen/Desktop/STA160/w2vdict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "down = pd.read_csv('/Users/zhanhaochen/Desktop/STA160/down.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.load('/Users/zhanhaochen/Desktop/STA160/test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(labels,(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [list(down.description[0:100])] + [list(down.description[-100:-1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vitaliy lives in the city of Melitopol. He is not married and works as a master of laying paving tiles. <br /><br />Vitaliy purchased a plot of land to develop. This year he would like to lay the fundament and build the walls of his future house. Vitaliy requests a loan of 120,000 hryvnia in order to start the construction. <br /><br />Thanks to the loan, Vitaliy will be able to hire a construction team, which can start working shortly. Vitaliy thanks the Kiva lenders in advance for the help with realizing his dreams - owning a house.',\n",
       " 'Liduvina attended school through the sixth grade. She has been married for more than 35 years and has 5 children.<br /> <br />Liduvina works in a bookstore—photocopier business that she decided to open with her husband 15 years ago because they saw it as a good income opportunity.<br /> <br />Thanks to her previous Kiva loan she was able to strengthen her business and as seen in the photograph it has remarkably improved. Her last loan is paid off already and she decided to apply for a new loan to buy a bookcase and pay to have her photocopy machine serviced.<br /> <br />She wants to keep her business going. She would also like to open a grocery store.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[down.description[0]] + [down.description[100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(i) for i in token_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# define documents\n",
    "docs = down.description\n",
    "# define class labels\n",
    "labels = test_label\n",
    "labels = np.array(labels).reshape(20000,1)\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 6050\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3504"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578.293598731818\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(down.description_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6050)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('the', 1), ('in', 2), ('a', 3), ('of', 4), ('to', 5), ('vitaliy', 6), ('and', 7), ('r', 8), ('br', 9), ('she', 10), ('her', 11), ('is', 12), ('loan', 13), ('n', 14), ('he', 15), ('married', 16), ('as', 17), ('this', 18), ('his', 19), ('house', 20), ('start', 21), ('construction', 22), ('thanks', 23), ('which', 24), ('for', 25), ('valentine', 26), ('sèmè', 27), ('podji', 28), ('children', 29), ('their', 30), ('school', 31), ('five', 32), ('years', 33), ('ago', 34), ('etc', 35), ('lives', 36), ('city', 37), ('melitopol', 38), ('not', 39), ('works', 40), ('master', 41), ('laying', 42), ('paving', 43), ('tiles', 44), ('purchased', 45), ('plot', 46), ('land', 47), ('develop', 48), ('year', 49), ('would', 50), ('like', 51), ('lay', 52), ('fundament', 53), ('build', 54), ('walls', 55), ('future', 56), ('requests', 57), ('120', 58), ('000', 59), ('hryvnia', 60), ('order', 61), ('will', 62), ('be', 63), ('able', 64), ('hire', 65), ('team', 66), ('can', 67), ('working', 68), ('shortly', 69), ('kiva', 70), ('lenders', 71), ('advance', 72), ('help', 73), ('with', 74), ('realizing', 75), ('dreams', 76), ('owning', 77), ('b', 78), ('was', 79), ('born', 80), ('1964', 81), ('benin', 82), ('appolinaire', 83), ('segla', 84), ('couple', 85), ('has', 86), ('four', 87), ('care', 88), ('two', 89), ('are', 90), ('own', 91), ('all', 92), ('attend', 93), ('nthe', 94), ('family', 95), ('settled', 96), ('pk10', 97), ('community', 98), ('almost', 99), ('seldom', 100), ('attended', 101), ('about', 102), ('started', 103), ('business', 104), ('selling', 105), ('food', 106), ('products', 107), ('maize', 108), ('beans', 109), ('rice', 110), ('trays', 111), ('fresh', 112), ('eggs', 113), ('palm', 114), ('oil', 115), ('soap', 116), ('gets', 117), ('stocks', 118), ('sells', 119), ('merchandise', 120), ('cotonou', 121), (\"benin's\", 122), ('economic', 123), ('capital', 124), ('nvalentine', 125), ('wishes', 126), ('bolster', 127), ('activity', 128), ('increase', 129), ('customer', 130), ('base', 131), ('result', 132), ('boost', 133), ('profits', 134), ('reason', 135), ('seeking', 136), ('new', 137), ('from', 138), ('alidé', 139)])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = w2vdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504, 100)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 36,  2, ...,  0,  0,  0],\n",
       "       [78, 26,  3, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Concatenate, Dense, Embedding, Flatten, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((41291,6050))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropped loan amount because it causes neural network produces worse result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "B1 (InputLayer)                 (None, 6050)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "A1 (InputLayer)                 (None, 310)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "B2 (Embedding)                  (None, 6050, 100)    4129100     B1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "A2 (Dense)                      (None, 512)          159232      A1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "LSTM (LSTM)                     (None, 100)          80400       B2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "A3 (Dense)                      (None, 256)          131328      A2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "B3 (Dense)                      (None, 64)           6464        LSTM[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 320)          0           A3[0][0]                         \n",
      "                                                                 B3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "C1 (Dense)                      (None, 320)          102720      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "C2 (Dense)                      (None, 128)          41088       C1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "C3 (Dense)                      (None, 1)            129         C2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 4,650,461\n",
      "Trainable params: 521,361\n",
      "Non-trainable params: 4,129,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A1 = Input(shape=(310,),name='A1')\n",
    "\n",
    "A2 = Dense(512, activation='relu',name='A2')(A1)\n",
    "A3 = Dense(256, activation='relu',name='A3')(A2)\n",
    "\n",
    "B1 = Input(shape=(6050,),name='B1')\n",
    "B2 = Embedding(vocab_size, 300 , weights=[embedding_matrix], input_length=6050, trainable=False, name = 'B2')(B1)\n",
    "B3 = LSTM(100,dropout=0.2,recurrent_dropout=0.2,name='LSTM')(B2)\n",
    "B4 = Dense(64, activation='relu',name='B3')(B3)\n",
    "\n",
    "merged = Concatenate()([A3,B4])\n",
    "C1 = Dense(320, activation='relu',name='C1')(merged)\n",
    "\n",
    "C2 = Dense(128, activation='relu',name='C2')(C1)\n",
    "C3 = Dense(1, activation='softmax',name='C3')(C2)\n",
    "model = Model(inputs=[A1,B1],outputs = C3)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "trainning = model.fit([comb_down,padded_docs], labels, epochs=20, batch_size=None, validation_split=0.1, \n",
    "          verbose=True, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, pad_train, pad_test= train_test_split(comb_down, test_label,padded_docs, test_size = 0.1, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([X_test,pad_test],y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
